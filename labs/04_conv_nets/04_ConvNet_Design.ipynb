{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConvNet design\n",
    "\n",
    "In this notebook we will design our own ConvNet and see some existing applications.\n",
    "\n",
    "We will also see the three different methods to define a Keras model:\n",
    "\n",
    "- Sequential\n",
    "- Functional\n",
    "- Object-Oriented\n",
    "\n",
    "The goal of this notebook is not to compare models performance, as we are limited on compute power, but to compare model architectures. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 2s 0us/step\n",
      "11501568/11490434 [==============================] - 2s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(((50000, 28, 28, 1), (50000,)),\n",
       " ((10000, 28, 28, 1), (10000,)),\n",
       " ((10000, 28, 28, 1), (10000,)))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()\n",
    "h, w = x_train.shape[1:]\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], h, w, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], h, w, 1)\n",
    "input_shape = (h, w, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    x_train, y_train, test_size=10000, random_state=42)\n",
    "\n",
    "(x_train.shape, y_train.shape), (x_val.shape, y_val.shape), (x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(x_train[0].squeeze(-1))\n",
    "plt.title(y_train[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9] unique labels.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"{} unique labels.\".format(np.unique(y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. LeNet\n",
    "\n",
    "Let's define a (slightly modified) LeNet model introduced by Yann Le Cun in 1998 ([paper url](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf)). The model is very simple and can be defined with the **Sequential** API.\n",
    "\n",
    "![lenet archi](images/lenet.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LeNet-5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " C1 (Conv2D)                 (None, 28, 28, 6)         156       \n",
      "                                                                 \n",
      " S2 (MaxPooling2D)           (None, 14, 14, 6)         0         \n",
      "                                                                 \n",
      " C3 (Conv2D)                 (None, 10, 10, 16)        2416      \n",
      "                                                                 \n",
      " S4 (AveragePooling2D)       (None, 5, 5, 16)          0         \n",
      "                                                                 \n",
      " C5 (Conv2D)                 (None, 1, 1, 120)         48120     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 120)               0         \n",
      "                                                                 \n",
      " F6 (Dense)                  (None, 84)                10164     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                850       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, AvgPool2D\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "lenet = Sequential(name=\"LeNet-5\")\n",
    "\n",
    "lenet.add(Conv2D(6, kernel_size=(5, 5), activation=\"tanh\", padding=\"same\", input_shape=input_shape, name=\"C1\"))\n",
    "lenet.add(MaxPool2D(pool_size=(2, 2), name=\"S2\"))\n",
    "lenet.add(Conv2D(16, kernel_size=(5, 5), activation='tanh', name=\"C3\"))\n",
    "lenet.add(AvgPool2D(pool_size=(2, 2), name=\"S4\"))\n",
    "lenet.add(Conv2D(120, kernel_size=(5, 5), activation='tanh', name=\"C5\"))\n",
    "lenet.add(Flatten())\n",
    "lenet.add(Dense(84, activation='tanh', name=\"F6\"))\n",
    "lenet.add(Dense(10, activation='softmax'))\n",
    "\n",
    "lenet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "196/196 [==============================] - ETA: 0s - loss: 0.6438 - accuracy: 0.8305"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-bd0fee48d880>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m lenet.fit(\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1250\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[0;32m-> 1252\u001b[0;31m           val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1253\u001b[0m               \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m               \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1536\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1537\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1538\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    947\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    950\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3128\u001b[0m       (graph_function,\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1959\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 256\n",
    "\n",
    "lenet.compile(\n",
    "    optimizer=optimizers.SGD(lr=0.1),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "lenet.fit(\n",
    "    x_train, y_train,\n",
    "    epochs=n_epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(x_val, y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that while LeNet was first defined using either `tanh` or `sigmoid`, those activations are now rarely used. As seen in Lab02, both activations saturate on very small and large values making their gradient almost null.\n",
    "\n",
    "Now most network use `ReLU` as hidden activation function or one of its derivative (https://keras.io/layers/advanced-activations/).\n",
    "\n",
    "## 2. Inception\n",
    "\n",
    "Inception models were introduced in 2014 by Szegedy et al. ([paper url](https://arxiv.org/abs/1409.4842)).\n",
    "\n",
    "Convolutions have an effective receptive field: the bigger the kernels, and the deeper the model, a features pixel will *see* more image pixels. Read this for a good explanation: [medium blog](https://medium.com/mlreview/a-guide-to-receptive-field-arithmetic-for-convolutional-neural-networks-e0f514068807).\n",
    "\n",
    "In Inception, convolution kernels of different sizes are combined. Small kernels see small clusters of features (think a detail as an eye) while big kernels see big clusters of features (think a face).\n",
    "\n",
    "![inception archi](images/inception.png)\n",
    "\n",
    "This time, use the **Functional** API to define a single Inception layer like the previous image\n",
    "Exemple usage:\n",
    "\n",
    "```python\n",
    "a = Input(shape=(32,))\n",
    "b = Dense(32)(a)\n",
    "model = Model(inputs=a, outputs=b)\n",
    "```\n",
    "\n",
    "The layer is first instancied (first pair of parenthesis) then called on a tensor (second set of parenthesis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Concatenate, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "def inception_layer(tensor, n_filters):\n",
    "    # TODO: define the 4 branches\n",
    "    branch1x1 = None\n",
    "    branch5x5 = None\n",
    "    branch3x3 = None\n",
    "    branch_pool = None\n",
    "\n",
    "    # TODO: merge it using Concatenate layer, use Concatenate? for more info\n",
    "    output = None\n",
    "    return output\n",
    "\n",
    "\n",
    "input_tensor = Input(shape=input_shape)\n",
    "x = Conv2D(16, kernel_size=(5, 5), padding=\"same\")(input_tensor)\n",
    "x = inception_layer(x, 32)\n",
    "x = Flatten()(x)\n",
    "output_tensor = Dense(10, activation=\"softmax\")(x)\n",
    "\n",
    "mini_inception = Model(inputs=input_tensor, outputs=output_tensor)\n",
    "\n",
    "mini_inception.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/mini_inception.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ResNet\n",
    "\n",
    "ResNet (*Residual Networks*) models were introduced by He et al. in 2015 ([paper url](https://arxiv.org/abs/1512.03385)). They found that more layers improved the performance but unfortunatly it was hard to backpropagate the gradients up to first layers.\n",
    "\n",
    "A trick to let the gradients \"*flow*\" easily is to use shortcut connection that let the forward tensor untouched (aka a *residual*):\n",
    "\n",
    "![resnet archi](images/resnet.png)\n",
    "\n",
    "This time, code a ResNet layer using the **Oriented-Object** API:\n",
    "\n",
    "Exemple usage:\n",
    "```python\n",
    "class MyModel(Model):\n",
    "    def __init__(self):\n",
    "        self.classifier = Dense(10, activation=\"softmax\")\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return self.classifier(inputs)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer, Add\n",
    "\n",
    "\n",
    "class ResidualBlock(Layer):\n",
    "    def __init__(self, n_filters):\n",
    "        super().__init__(name=\"ResidualBlock\")\n",
    "        \n",
    "        # TODO: define needed layers, use Add to combine the shortcut with the convs' output.\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # TODO\n",
    "        return 42\n",
    "    \n",
    "\n",
    "class MiniResNet(Model):\n",
    "    def __init__(self, n_filters):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = Conv2D(n_filters, kernel_size=(5, 5), padding=\"same\")\n",
    "        self.block = ResidualBlock(n_filters)\n",
    "        self.flatten = Flatten()\n",
    "        self.classifier = Dense(10, activation=\"softmax\")\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # TODO\n",
    "        return 1337\n",
    "\n",
    "\n",
    "mini_resnet = MiniResNet(32)\n",
    "mini_resnet.build((None, *input_shape))\n",
    "mini_resnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/mini_resnet.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Batch Normalization\n",
    "\n",
    "Batch Normalization is not an architecture but a layer. Introduced by Ioffe et al. in 2015 ([paper url](https://arxiv.org/abs/1502.03167)). Here is an extract from their abstract:\n",
    "\n",
    "> Training Deep Neural Networks is complicated by the fact that the **distribution of each layer’s inputs changes during training, as the parameters of the previous layers change**. This slows down the training by requiring lower learningrates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities.  We refer to this phenomenon as **internal covariate shift**, and address the problem by **normalizing layer inputs**.\n",
    "\n",
    "The results are that ConvNet trained with BatchNorm converge faster and with better results. Nowadays all (or almost all) networks are use it or one of its variants. See this [article on normalization](https://arthurdouillard.com/post/normalization/) for more info."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classic block is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(Layer):\n",
    "    def __init__(n_filters, kernel_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv = Conv2D(n_filters, kernel_size=kernel_size, use_bias=False)\n",
    "        self.bn = BatchNormalization(axis=3)\n",
    "        self.activation = Activation(\"relu\")\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return self.activation(\n",
    "            self.bn(self.conv(inputs))\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That you can place multiple times into your network as Lego blocks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Separable Convolutions\n",
    "\n",
    "ConvNet usually have a lot of parameters because of their large depth. A trick to trim the number of parameters with minimal performance loss is to use **separable convolution**.\n",
    "\n",
    "The standard convolution has quite a lot of parameters (but still much less than a Fully Connected layer!):\n",
    "\n",
    "![conv](images/conv.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model = Sequential(name=\"Conv Model\")\n",
    "conv_model.add(Conv2D(8, kernel_size=(3, 3), use_bias=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice: \n",
    "\n",
    "- How many parameters does this convolution has?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_model.build((None, *input_shape))\n",
    "# conv_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separable convolutions are made of two convolutions:\n",
    "\n",
    "- A **depthwise convolution**, a single kernel is created per input channels, spatial information is affected, but channels information is not shared\n",
    "\n",
    "![depthwise conv](images/depthwise.png)\n",
    "\n",
    "- A **pointwise convolution**, is a usual convolution with a kernel of size (1, 1). Spatial information is not affected, but channels information is shared.\n",
    "\n",
    "![pointwise conv](images/pointwise.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import DepthwiseConv2D\n",
    "\n",
    "separable_model = Sequential(name=\"Separable Model\")\n",
    "separable_model.add(DepthwiseConv2D(kernel_size=(3, 3), use_bias=False))\n",
    "separable_model.add(Conv2D(8, kernel_size=(1, 1), use_bias=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercice:\n",
    "\n",
    "- How many parameters does the Depthwise convolution has?\n",
    "- How many parameters does the Pointwise convolution has?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separable_model.build((None, *input_shape))\n",
    "# separable_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Home assignments\n",
    "\n",
    "- See the different models available on Keras: https://keras.io/applications/ What are their different architecture tricks?\n",
    "- Try to pick an architecture (like [MobileNet](https://arxiv.org/abs/1704.04861) or [Squeeze-and-Excitation network](https://arxiv.org/abs/1709.01507)), read their paper, implement it in Keras, and try to reach good performance on a small dataset like CIFAR10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
